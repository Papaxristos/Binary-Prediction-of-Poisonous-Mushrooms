import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, matthews_corrcoef, confusion_matrix
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder
from joblib import dump, load
import tkinter as tk
from tkinter import filedialog
import shutil

# Function to select a CSV file
def select_csv_file(title):
    root = tk.Tk()
    root.withdraw()  # Hide the root window
    file_path = filedialog.askopenfilename(title=title, filetypes=[("CSV files", "*.csv")])
    return file_path

# Function to select a folder for saving files
def select_save_folder():
    root = tk.Tk()
    root.withdraw()  # Hide the root window
    folder_path = filedialog.askdirectory(title="Select a folder to save files")
    return folder_path

# Select train and test CSV files
train_file_path = select_csv_file("Select the training CSV file")
test_file_path = select_csv_file("Select the test CSV file")

# Load the train and test datasets using pandas
train_data = pd.read_csv(train_file_path)
test_data = pd.read_csv(test_file_path)

# Display the first few rows of the train and test datasets
print("Train Data:")
print(train_data.head())

print("\nTest Data:")
print(test_data.head())

# Splitting features (X) and labels (y)
label_column = 'class'

if label_column not in train_data.columns:
    raise KeyError(f"Training data must contain the column '{label_column}'")

X = train_data.drop(columns=[label_column])
y = train_data[label_column]

# Splitting the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Identify categorical and numerical features
categorical_features = X.select_dtypes(include=['object']).columns
numerical_features = X.select_dtypes(include=['number']).columns

# Create transformers
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='mean')),
            ('scaler', StandardScaler())
        ]), numerical_features),
        ('cat', Pipeline(steps=[
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('onehot', OneHotEncoder(handle_unknown='ignore'))
        ]), categorical_features)
    ])

# Define initial model with XGBoost
model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', XGBClassifier(eval_metric='mlogloss', random_state=42))
])

# Train the model with training data
model.fit(X_train, y_train)

# Evaluate the model with validation data
y_val_pred = model.predict(X_val)

# Compute evaluation metrics for validation data
accuracy = accuracy_score(y_val, y_val_pred)
print(f"Validation Accuracy: {accuracy:.4f}")

# Select the save folder
save_folder = select_save_folder()

# Save the trained model and metrics
model_path = os.path.join(save_folder, 'trained_model.joblib')
dump(model, model_path)
print(f"Model saved to: {model_path}")

# Save the classification report
report_path = os.path.join(save_folder, 'classification_report.csv')
report_df = pd.DataFrame(classification_report(y_val, y_val_pred, output_dict=True)).transpose()
report_df.to_csv(report_path)
print(f"Classification report saved to: {report_path}")

# Save the confusion matrix
conf_matrix = confusion_matrix(y_val, y_val_pred)
conf_matrix_path = os.path.join(save_folder, 'confusion_matrix.csv')
pd.DataFrame(conf_matrix).to_csv(conf_matrix_path, index=False)
print(f"Confusion matrix saved to: {conf_matrix_path}")
